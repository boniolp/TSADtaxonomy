{
  "name": "IForest",
  "full_name": "Isolation Forest",
  "category": "Tree-based",
  "Dim": "Univariate",
  "Sup": "Unsupervised",
  "Stream": false,
  "year": 2008,
  "authors": ["Fei Tony Liu", "Kai Ming Ting", "Zhi-Hua Zhou"],
  "paper": "Isolation Forest. In ICDM",
  "description": "Isolation Forest (IForest) is a density-based and tree-based anomaly detection method. It isolates anomalies using random partitioning of the data space. The core assumption is that anomalies are easier to isolate, requiring fewer random splits. Therefore, instances that require fewer partitions are more likely to be anomalous. This method is fast, effective, and particularly well-suited to time series anomaly detection tasks. The TSB-UAD implementation wraps Scikit-learnâ€™s IsolationForest and provides time series-specific preprocessing and visualization tools.",
  "code": "https://github.com/TheDatumOrg/TSB-UAD",
  "url": "https://www.lamda.nju.edu.cn/publication/icdm08b.pdf",
  "bibtex": "@inproceedings{liu2008isolation, title={Isolation forest}, author={Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua}, booktitle={2008 Eighth IEEE International Conference on Data Mining}, pages={413--422}, year={2008}, organization={IEEE}}",
  "snippet_description": "We provide below an example of usage of Isolation Forest for time series anomaly detection (from TSB-UAD benchmark). Please install TSB-UAD as follows:",
  "snippet_install": "pip install tsb-uad",
  "snippet": "```python\nimport os\nimport math\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom TSB_UAD.utils.visualisation import plotFig\nfrom TSB_UAD.models.iforest import IForest\nfrom TSB_UAD.models.feature import Window\nfrom TSB_UAD.utils.slidingWindows import find_length\nfrom TSB_UAD.vus.metrics import get_metrics\n\n# Read data\nfilepath = 'PATH_TO_TSB_UAD/ECG/MBA_ECG805_data.out'\ndf = pd.read_csv(filepath, header=None).dropna().to_numpy()\nname = filepath.split('/')[-1]\n\ndata = df[:,0].astype(float)\nlabel = df[:,1].astype(int)\n\n# Pre-processing\nslidingWindow = find_length(data)\nX_data = Window(window=slidingWindow).convert(data).to_numpy()\n\n# Run IForest\nmodelName = 'IForest'\nclf = IForest(n_jobs=1)\nclf.fit(X_data)\nscore = clf.decision_scores_\n\n# Post-processing\nscore = MinMaxScaler(feature_range=(0,1)).fit_transform(score.reshape(-1,1)).ravel()\nscore = np.array([score[0]]*math.ceil((slidingWindow-1)/2) + list(score) + [score[-1]]*((slidingWindow-1)//2))\n\n# Plot result\nplotFig(data, label, score, slidingWindow, fileName=name, modelName=modelName)\n\n# Print accuracy\nresults = get_metrics(score, label, metric=\"all\", slidingWindow=slidingWindow)\nfor metric in results.keys():\n    print(metric, ':', results[metric])\n```",
  "figure_result": ""
}
